{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Processing of Language "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to compare documents\n",
    " - topic modeling/reducing dimensionality of features: \n",
    "     - Linear Discriminant Analysis (get mean of the classes and then draw a line between them)\n",
    "         - this is supervised\n",
    "         - efficient in terms of complexity\n",
    "     - Latent Semantic Analysis (try to pick up on topics that are not explicitly there)\n",
    "         - pretty much SVD/matrix factorization\n",
    "         - gets out principal components which are the features that explain x% of the variance\n",
    "         - meaning of a word is the average of the words around it?\n",
    "     - Latent Dirichlet Allocation\n",
    "         - uses distribution?\n",
    "         \n",
    "- similarity metrics\n",
    "    - cosine similarity - angle b/w two vectors\n",
    "    \n",
    "- keeping semantic meaning:\n",
    "    - word2vec: neural network to predict words that are near the target to find how it is related to other words (not trying to predic the meaning of the word); looks at every subset of 5 words\n",
    "    - GloVe: \"global representation of word vectors\", no neural nets just SVD; looks at ALL words in document/corps\n",
    "    \n",
    "    \n",
    "- sentiment\n",
    "    - VADER - Valence Aware Dictionary for Sentiment Reasoning; just tagged sentiment of words from twitter?\n",
    "        - if word is not in the dict here, you can't use it?\n",
    "    - TextBlog\n",
    "    - Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* review\n",
    "* spelling\n",
    "* similarity\n",
    "* sentiment\n",
    "* languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_today = \"\"\"Beautiful is better than ugly.\n",
    "Explicit is better than implicit.\n",
    "Simple is better than complex.\n",
    "Complex is better than complicated.\n",
    "Flat is better than nested.\n",
    "Sparse is better than dense.\n",
    "Readability counts.\n",
    "Special cases aren't special enough to break the rules.\n",
    "Although practicality beats purity.\n",
    "Errors should never pass silently.\n",
    "Unless explicitly silenced.\n",
    "In the face of ambiguity, refuse the temptation to guess.\n",
    "There should be one-- and preferably only one --obvious way to do it.\n",
    "Although that way may not be obvious at first unless you're Dutch.\n",
    "Now is better than never.\n",
    "Although never is often better than *right* now.\n",
    "If the implementation is hard to explain, it's a bad idea.\n",
    "If the implementation is easy to explain, it may be a good idea.\n",
    "Namespaces are one honking great idea -- let's do more of those!\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = TextBlob(text_today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob.blob.TextBlob"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what can we get from textblob\n",
    "type(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Beautiful', 'is', 'better', 'than', 'ugly', 'Explicit', 'is', 'better', 'than', 'implicit', 'Simple', 'is', 'better', 'than', 'complex', 'Complex', 'is', 'better', 'than', 'complicated', 'Flat', 'is', 'better', 'than', 'nested', 'Sparse', 'is', 'better', 'than', 'dense', 'Readability', 'counts', 'Special', 'cases', 'are', \"n't\", 'special', 'enough', 'to', 'break', 'the', 'rules', 'Although', 'practicality', 'beats', 'purity', 'Errors', 'should', 'never', 'pass', 'silently', 'Unless', 'explicitly', 'silenced', 'In', 'the', 'face', 'of', 'ambiguity', 'refuse', 'the', 'temptation', 'to', 'guess', 'There', 'should', 'be', 'one', 'and', 'preferably', 'only', 'one', 'obvious', 'way', 'to', 'do', 'it', 'Although', 'that', 'way', 'may', 'not', 'be', 'obvious', 'at', 'first', 'unless', 'you', \"'re\", 'Dutch', 'Now', 'is', 'better', 'than', 'never', 'Although', 'never', 'is', 'often', 'better', 'than', 'right', 'now', 'If', 'the', 'implementation', 'is', 'hard', 'to', 'explain', 'it', \"'s\", 'a', 'bad', 'idea', 'If', 'the', 'implementation', 'is', 'easy', 'to', 'explain', 'it', 'may', 'be', 'a', 'good', 'idea', 'Namespaces', 'are', 'one', 'honking', 'great', 'idea', 'let', \"'s\", 'do', 'more', 'of', 'those'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Beautiful', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('better', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('ugly', 'RB'),\n",
       " ('Explicit', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('better', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('implicit', 'NN'),\n",
       " ('Simple', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('better', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('complex', 'JJ'),\n",
       " ('Complex', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('better', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('complicated', 'VBN'),\n",
       " ('Flat', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('better', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('nested', 'VBN'),\n",
       " ('Sparse', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('better', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('dense', 'NN'),\n",
       " ('Readability', 'NN'),\n",
       " ('counts', 'NNS'),\n",
       " ('Special', 'JJ'),\n",
       " ('cases', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('special', 'JJ'),\n",
       " ('enough', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('break', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('rules', 'NNS'),\n",
       " ('Although', 'IN'),\n",
       " ('practicality', 'NN'),\n",
       " ('beats', 'NNS'),\n",
       " ('purity', 'NN'),\n",
       " ('Errors', 'NNS'),\n",
       " ('should', 'MD'),\n",
       " ('never', 'RB'),\n",
       " ('pass', 'VB'),\n",
       " ('silently', 'RB'),\n",
       " ('Unless', 'IN'),\n",
       " ('explicitly', 'RB'),\n",
       " ('silenced', 'VBN'),\n",
       " ('In', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('face', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('ambiguity', 'NN'),\n",
       " ('refuse', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('temptation', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('guess', 'VB'),\n",
       " ('There', 'EX'),\n",
       " ('should', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('one', 'CD'),\n",
       " ('and', 'CC'),\n",
       " ('preferably', 'RB'),\n",
       " ('only', 'RB'),\n",
       " ('one', 'CD'),\n",
       " ('obvious', 'JJ'),\n",
       " ('way', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('do', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('Although', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('may', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('obvious', 'JJ'),\n",
       " ('at', 'IN'),\n",
       " ('first', 'JJ'),\n",
       " ('unless', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " (\"'re\", 'VBP'),\n",
       " ('Dutch', 'JJ'),\n",
       " ('Now', 'RB'),\n",
       " ('is', 'VBZ'),\n",
       " ('better', 'RBR'),\n",
       " ('than', 'IN'),\n",
       " ('never', 'RB'),\n",
       " ('Although', 'IN'),\n",
       " ('never', 'RB'),\n",
       " ('is', 'VBZ'),\n",
       " ('often', 'RB'),\n",
       " ('better', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('*right*', 'RB'),\n",
       " ('now', 'RB'),\n",
       " ('If', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('implementation', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('hard', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('explain', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('bad', 'JJ'),\n",
       " ('idea', 'NN'),\n",
       " ('If', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('implementation', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('easy', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('explain', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('may', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('good', 'JJ'),\n",
       " ('idea', 'NN'),\n",
       " ('Namespaces', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('one', 'CD'),\n",
       " ('honking', 'VBG'),\n",
       " ('great', 'JJ'),\n",
       " ('idea', 'NN'),\n",
       " ('let', 'VB'),\n",
       " (\"'s\", 'POS'),\n",
       " ('do', 'VB'),\n",
       " ('more', 'JJR'),\n",
       " ('of', 'IN'),\n",
       " ('those', 'DT')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parts of Speech\n",
    "wiki.pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['beautiful', 'explicit', 'simple', 'complex', 'flat', 'sparse', 'readability', 'special cases', 'practicality beats purity', 'errors', 'unless', 'obvious way', 'dutch', 'bad idea', 'good idea', 'namespaces', 'great idea'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nouns?\n",
    "wiki.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'octopus'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word(\"octopi\")\n",
    "w.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how would we change the part of speech?\n",
    "w = Word(\"went\")\n",
    "w.lemmatize(pos='v')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spellling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### there is also a spellchecker with textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = TextBlob(\"I havv goood speling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"I have good spelling\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell.correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity between Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the similarity between documents, normalizing for size, take the cosine similarity between the two \n",
    "<br>\n",
    "This creates a metric from [0,1] of how 'similar' the documents are, which will might see in recommendation engines..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_docs = CountVectorizer()\n",
    "sim_corpus = ['I ate a burger at burger queen and it was very good.',\n",
    "           'I ate a hot dog at burger prince and it was bad',\n",
    "          'I drove a racecar through your kitchen door',\n",
    "          'I ate a hot dog at burger king and it was bad. I ate a burger at burger queen and it was very good']\n",
    "sim_vector = sim_docs.fit_transform(sim_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ate': 2,\n",
       " 'burger': 4,\n",
       " 'at': 1,\n",
       " 'queen': 14,\n",
       " 'and': 0,\n",
       " 'it': 10,\n",
       " 'was': 18,\n",
       " 'very': 17,\n",
       " 'good': 8,\n",
       " 'hot': 9,\n",
       " 'dog': 5,\n",
       " 'prince': 13,\n",
       " 'bad': 3,\n",
       " 'drove': 7,\n",
       " 'racecar': 15,\n",
       " 'through': 16,\n",
       " 'your': 19,\n",
       " 'kitchen': 12,\n",
       " 'door': 6,\n",
       " 'king': 11}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_docs.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>at</th>\n",
       "      <th>ate</th>\n",
       "      <th>bad</th>\n",
       "      <th>burger</th>\n",
       "      <th>dog</th>\n",
       "      <th>door</th>\n",
       "      <th>drove</th>\n",
       "      <th>good</th>\n",
       "      <th>hot</th>\n",
       "      <th>it</th>\n",
       "      <th>king</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>prince</th>\n",
       "      <th>queen</th>\n",
       "      <th>racecar</th>\n",
       "      <th>through</th>\n",
       "      <th>very</th>\n",
       "      <th>was</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  at  ate  bad  burger  dog  door  drove  good  hot  it  king  kitchen  \\\n",
       "0    1   1    1    0       2    0     0      0     1    0   1     0        0   \n",
       "\n",
       "   prince  queen  racecar  through  very  was  your  \n",
       "0       0      1        0        0     1    1     0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(sim_vector[0])\n",
    "print(type(sim_vector[0]))\n",
    "df_sim_0 = pd.DataFrame(sim_vector[0].toarray(), columns=sim_docs.get_feature_names())\n",
    "df_sim_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63900965]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(sim_vector[0], sim_vector[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I ate a burger at burger queen and it was very good.',\n",
       " 'I ate a hot dog at burger prince and it was bad',\n",
       " 'I drove a racecar through your kitchen door',\n",
       " 'I ate a hot dog at burger king and it was bad. I ate a burger at burger queen and it was very good']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 2)\t1\n"
     ]
    }
   ],
   "source": [
    "print(sim_vector[1])\n",
    "df_sim_1 = pd.DataFrame(sim_vector[1].toarray(), columns=sim_docs.get_feature_names())\n",
    "# df_sim_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(sim_vector[3], sim_vector[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim implementation of word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import summarize, keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Simple is better than complex.\\nComplex is better than complicated.\\nIf the implementation is hard to explain, it's a bad idea.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize a document \n",
    "summarize(text_today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'idea\\nbeats\\npurity\\ncases\\nreadability\\ngreat'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords(text_today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[0m\n\n  Searched in:\n    - '/Users/Kristinabarounis/nltk_data'\n    - '/Users/Kristinabarounis/anaconda3/nltk_data'\n    - '/Users/Kristinabarounis/anaconda3/share/nltk_data'\n    - '/Users/Kristinabarounis/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-23099ade2833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lexicon_file)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlexicon_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     ):\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexicon_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexicon_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexicon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_lex_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[0m\n\n  Searched in:\n    - '/Users/Kristinabarounis/nltk_data'\n    - '/Users/Kristinabarounis/anaconda3/nltk_data'\n    - '/Users/Kristinabarounis/anaconda3/share/nltk_data'\n    - '/Users/Kristinabarounis/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "si = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_test = \"I love you\"\n",
    "vader_test_2 = \"not great... but the pasta is ok\"\n",
    "vader_test_3 = \"I don't think this is a good idea\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si.polarity_scores(vader_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.19472222222222227, subjectivity=0.5595238095238095)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# think about attributes...\n",
    "wiki.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Beautiful is better than ugly.\n",
       "Explicit is better than implicit.\n",
       "Simple is better than complex.\n",
       "Complex is better than complicated.\n",
       "Flat is better than nested.\n",
       "Sparse is better than dense.\n",
       "Readability counts.\n",
       "Special cases aren't special enough to break the rules.\n",
       "Although practicality beats purity.\n",
       "Errors should never pass silently.\n",
       "Unless explicitly silenced.\n",
       "In the face of ambiguity, refuse the temptation to guess.\n",
       "There should be one-- and preferably only one --obvious way to do it.\n",
       "Although that way may not be obvious at first unless you're Dutch.\n",
       "Now is better than never.\n",
       "Although never is often better than *right* now.\n",
       "If the implementation is hard to explain, it's a bad idea.\n",
       "If the implementation is easy to explain, it may be a good idea.\n",
       "Namespaces are one honking great idea -- let's do more of those!\")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# autres langues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_blob = TextBlob(u\"美丽优于丑陋\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Beauty is better than ugly\")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_blob.translate(from_lang=\"zh-CN\", to='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = TextBlob(u\"بسيط هو أفضل من مجمع\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ar'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
